<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Posters BioVis@VIS</title>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.97.5/css/materialize.min.css"/>
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,600,300' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/2016/css/main.css">
</head>


<body class="site">

    <div class="body">
    <nav>
        <div class="nav-wrapper">

            <ul id="vis" class="dropdown-content">
                <li><a href="/2016/ieeevis">Overview</a></li>
                <li class="divider">
                <li><a href="/2016/cfp_vis">Call for Participation</a></li>
                <li><a href="/2016/papers">Paper Submission</a></li>
                <li><a href="/2016/posters_ieee">Poster Submission</a></li>
                <li><a href="/2016/designContest_vis">Design Contest</a></li>
                <li class="divider"></li>
                <li><a href="/2016/program_ieee">Program</a></li>
            </ul>
            <ul id="ismb" class="dropdown-content">
                <li><a href="/2016/ismb">Overview</a></li>
                <li class="divider"></li>
                <li><a href="/2016/cfp_ismb">Call for Participation</a></li>
                <li><a href="/2016/submission_ismb">Abstract Submission</a></li>
                <li><a href="/2016/registration_ismb">Registration</a></li>
                <li class="divider"></li>
                <li><a href="/2016/program_ismb">Program</a></li>
                <!--<li><a href="/2016/posters_ismbAccepted">Accepted Posters</a></li>-->
            </ul>

            <a href="/2016/" class="brand-logo"><img src="/2016/images/logo-white.svg"
                                                                  width="150"/></a>
            <a href="#" data-activates="mobile" class="button-collapse"><i class="material-icons">menu</i></a>
            <ul class="right hide-on-med-and-down">
                <li><a class="dropdown-button" href="#!" data-beloworigin="true" data-activates="vis">@IEEE VIS<i
                        class="material-icons right">arrow_drop_down</i></a></li>
                <li><a class="dropdown-button" href="#!" data-beloworigin="true" data-activates="ismb">@ISMB<i
                        class="material-icons right">arrow_drop_down</i></a></li>
                <li><a href="/2016/dream">@DREAM</a></li>

                <li><a href="/2016/committee.html">Organizing Committee</a></li>
                <li><a href="/2016/previousYears/">Previous Years</a></li>
            </ul>
            <ul class="side-nav" id="mobile">
                <li><a href="/2016/ieeevis/">@IEEE VIS 2016</a>
                    <ul>
                        <li><a href="/2016/cfp_vis">Call for Participation</a></li>
                        <li><a href="/2016/papers">Paper Submission</a></li>
                        <li><a href="/2016/posters_ieee">Poster Submission</a></li>
                        <li><a href="/2016/designContest_vis">Design Contest</a></li>
                        <li><a href="/2016/program_ieee">Program</a></li>
                    </ul>
                </li>

                <li><a href="/2016/ismb/">@ISMB 2016</a>
                    <ul>
                        <li><a href="/2016/cfp_ismb">Call for Participation</a></li>
                        <li><a href="/2016/submission_ismb">Abstract Submission</a></li>
                        <li><a href="/2016/program_ismb">Program</a></li>
                    </ul>
                </li>
                <li><a href="/2016/previousYears/">Previous Years</a></li>
            </ul>
        </div>
    </nav>


    <div class="breadcrumbs moduletable">
  <ul class="breadcrumb">
    <li class="active">You are here: &nbsp;</li>
    <li><a href="/2016/" class="pathway">Home</a> |</li>
    
    <li><a href="/2016/ieee" class="pathway">VIS 2016</a> |</li>
    
    <li class="active"><span>Posters BioVis@VIS</span></li>
  </ul>
</div>

<div class="blue-section">
  <h3 itemprop="name">Posters BioVis@VIS</h3>
</div>

<div class="container">
<!--**Attention Poster Authors:**
When preparing accepted posters please note that your poster should not exceed the following dimensions: *46 inches wide by 45 inches high*. There will be 2 posters per side on the each poster board. One poster will be an odd number and the other will be an even number. View a diagram of the the poster board in pdf format [here](http://www.iscb.org/images/stories/ismb2016/downloads/ISMB2016-PosterSampler.pdf).
-->

<div class="talk">
  <table>
  <tr>
    <td width="300px">
      <a href="/2016/files/vis-105-thumbnail.png"> <img style="padding-right: 10px;" src="/2016/files/vis-105-thumbnail.png" alt="Visualizing the Trajectories and Contexts of Facial Branchiomotor Neuron Pioneers" height="250" width="250" /></a>
    </td>
  <td>
    <div class="ttitle">Poster: Visualizing the Trajectories and Contexts of Facial Branchiomotor Neuron Pioneers</div>
    <div><span class="tspeaker">Tri Huynh, Anastasia Beiriger, Victoria Prince, Gordon Kindlmann</span></div>
    <div>
      <p>A crucial part of nervous system development in vertebrate embryos is migration of neurons from initial birth-place to final destinations within the brain. The migration trajectories are fundamental to proper brain wiring. Recently we showed that within the neurons of the facial nerve, a single "pioneer" neuron guides movement of the remaining neurons. Basic questions remain: Where do pioneer neurons come from, how do they know where to go, and how do other neurons know how to follow them? We are studying the pioneer neurons that lead facial branchiomotor neurons (FBMNs) of zebrafish embryos via light-sheet microscopy imaging. Technical and scientific challenges drive our visualization research. Imaging one embryo (over about 8 hours) generates a terabyte of two-channel image data (GFP for nuclei, RFP for cell membranes). The data size and the ventral location of the FBMN (limiting image quality) impede simple application of existing automated cell trackers. The two FBMN pioneers can be identified by an expert near the end of the experiment, but must then be tracked back in time and position to their birth.  Empowering and augmenting this expert analysis is a novel visualization design challenge. Answering the driving scientific questions will require new ways to visually summarize recovered pioneer trajectories and their cellular context over space and time, to identify the factors determining their structure. In work to date, we developed visualizations of time-steps with annotated pioneer locations, and are now developing interfaces to select and display a time-step for a particular point along the trajectory.</p>
    </div>
    <!--<div><span><a href="/2016/files/A crucial part of nervous system development in vertebrate embryos is migration of neurons from initial birth-place to final destinations within the brain. The migration trajectories are fundamental to proper brain wiring. Recently we showed that within the neurons of the facial nerve, a single "pioneer" neuron guides movement of the remaining neurons. Basic questions remain: Where do pioneer neurons come from, how do they know where to go, and how do other neurons know how to follow them? We are studying the pioneer neurons that lead facial branchiomotor neurons (FBMNs) of zebrafish embryos via light-sheet microscopy imaging. Technical and scientific challenges drive our visualization research. Imaging one embryo (over about 8 hours) generates a terabyte of two-channel image data (GFP for nuclei, RFP for cell membranes). The data size and the ventral location of the FBMN (limiting image quality) impede simple application of existing automated cell trackers. The two FBMN pioneers can be identified by an expert near the end of the experiment, but must then be tracked back in time and position to their birth.  Empowering and augmenting this expert analysis is a novel visualization design challenge. Answering the driving scientific questions will require new ways to visually summarize recovered pioneer trajectories and their cellular context over space and time, to identify the factors determining their structure. In work to date, we developed visualizations of time-steps with annotated pioneer locations, and are now developing interfaces to select and display a time-step for a particular point along the trajectory.">Download Full Abstract</a></span></div>-->
  </td>
  </tr>
  </table>
  <!--
  <div class="clearfix float-my-children">
    <div><img src="/2016/files/vis-105-thumbnail.png" alt="Visualizing the Trajectories and Contexts of Facial Branchiomotor Neuron Pioneers" height="125" width="125"></div>
    <div>
      <div class="ttitle">Poster: Visualizing the Trajectories and Contexts of Facial Branchiomotor Neuron Pioneers</div>
      <div><span class="tspeaker">Tri Huynh, Anastasia Beiriger, Victoria Prince, Gordon Kindlmann</span></div>
      <div><span><a href="/2016/files/A crucial part of nervous system development in vertebrate embryos is migration of neurons from initial birth-place to final destinations within the brain. The migration trajectories are fundamental to proper brain wiring. Recently we showed that within the neurons of the facial nerve, a single "pioneer" neuron guides movement of the remaining neurons. Basic questions remain: Where do pioneer neurons come from, how do they know where to go, and how do other neurons know how to follow them? We are studying the pioneer neurons that lead facial branchiomotor neurons (FBMNs) of zebrafish embryos via light-sheet microscopy imaging. Technical and scientific challenges drive our visualization research. Imaging one embryo (over about 8 hours) generates a terabyte of two-channel image data (GFP for nuclei, RFP for cell membranes). The data size and the ventral location of the FBMN (limiting image quality) impede simple application of existing automated cell trackers. The two FBMN pioneers can be identified by an expert near the end of the experiment, but must then be tracked back in time and position to their birth.  Empowering and augmenting this expert analysis is a novel visualization design challenge. Answering the driving scientific questions will require new ways to visually summarize recovered pioneer trajectories and their cellular context over space and time, to identify the factors determining their structure. In work to date, we developed visualizations of time-steps with annotated pioneer locations, and are now developing interfaces to select and display a time-step for a particular point along the trajectory.">Download
          Full Abstract</a></span></div>
    </div>
  </div>
  -->
</div>

<div class="talk">
  <table>
  <tr>
    <td width="300px">
      <a href="/2016/files/vis-106-thumbnail.png"> <img style="padding-right: 10px;" src="/2016/files/vis-106-thumbnail.png" alt="Co-visualisation of Close Genetic Relatedness of Mycobacterium Tuberculosis Isolates with Complex Meta-Data" height="250" width="250" /></a>
    </td>
  <td>
    <div class="ttitle">Poster: Co-visualisation of Close Genetic Relatedness of Mycobacterium Tuberculosis Isolates with Complex Meta-Data</div>
    <div><span class="tspeaker">Trien V. Do, Oriol Mazariegos Canellas, Derrick Crook, Tim Peto, David Wyllie</span></div>
    <div>
      <p>Routine DNA sequencing of all Mycobacterium tuberculosis samples isolated in England is projected to be operational within the next 12 months. We have recently created a web application which allows identification of closely genetically related samples and storage of meta-data about the individuals from whom they were obtained. This capability is of interest since breaking chains of transmission depends on their rapid identification and pairs of individuals with highly related samples are more likely to have transmitted to each other. However, prioritising interventions requires expert review of the genetic relationships, intervals between isolation, location, and individual risk factors, inter alia. This paper presents a visualisation approach to address this issue. A user (e.g. a public health doctor, or TB control nurse) logs into the web application then can select sets of individuals of interest, either by date, name, specimen number, or genetic relatedness to all cases. In 'set of samples' mode, the application allows residential addresses, times of isolation, and genetic relationships to be co-visualised for a sample set in a map view and a timeline. In 'single case exploration' mode, links between a single case and others can be displayed, with metadata displayed in tooltip like format (e.g. name, age, address, history, resistance, contact number). The user can 'Explore from here', upon which the current sample will become a new target sample. Thus, iterative exploration of transmission networks is possible. This application is being co-developed and evaluated between the University of Oxford and Public Health England TB control professionals.</p>
    </div>
    <!--<div><span><a href="/2016/files/Routine DNA sequencing of all Mycobacterium tuberculosis samples isolated in England is projected to be operational within the next 12 months. We have recently created a web application which allows identification of closely genetically related samples and storage of meta-data about the individuals from whom they were obtained. This capability is of interest since breaking chains of transmission depends on their rapid identification and pairs of individuals with highly related samples are more likely to have transmitted to each other. However, prioritising interventions requires expert review of the genetic relationships, intervals between isolation, location, and individual risk factors, inter alia. This paper presents a visualisation approach to address this issue. A user (e.g. a public health doctor, or TB control nurse) logs into the web application then can select sets of individuals of interest, either by date, name, specimen number, or genetic relatedness to all cases. In 'set of samples' mode, the application allows residential addresses, times of isolation, and genetic relationships to be co-visualised for a sample set in a map view and a timeline. In 'single case exploration' mode, links between a single case and others can be displayed, with metadata displayed in tooltip like format (e.g. name, age, address, history, resistance, contact number). The user can 'Explore from here', upon which the current sample will become a new target sample. Thus, iterative exploration of transmission networks is possible. This application is being co-developed and evaluated between the University of Oxford and Public Health England TB control professionals.">Download Full Abstract</a></span></div>-->
  </td>
  </tr>
  </table>
  <!--
  <div class="clearfix float-my-children">
    <div><img src="/2016/files/vis-106-thumbnail.png" alt="Co-visualisation of Close Genetic Relatedness of Mycobacterium Tuberculosis Isolates with Complex Meta-Data" height="125" width="125"></div>
    <div>
      <div class="ttitle">Poster: Co-visualisation of Close Genetic Relatedness of Mycobacterium Tuberculosis Isolates with Complex Meta-Data</div>
      <div><span class="tspeaker">Trien V. Do, Oriol Mazariegos Canellas, Derrick Crook, Tim Peto, David Wyllie</span></div>
      <div><span><a href="/2016/files/Routine DNA sequencing of all Mycobacterium tuberculosis samples isolated in England is projected to be operational within the next 12 months. We have recently created a web application which allows identification of closely genetically related samples and storage of meta-data about the individuals from whom they were obtained. This capability is of interest since breaking chains of transmission depends on their rapid identification and pairs of individuals with highly related samples are more likely to have transmitted to each other. However, prioritising interventions requires expert review of the genetic relationships, intervals between isolation, location, and individual risk factors, inter alia. This paper presents a visualisation approach to address this issue. A user (e.g. a public health doctor, or TB control nurse) logs into the web application then can select sets of individuals of interest, either by date, name, specimen number, or genetic relatedness to all cases. In 'set of samples' mode, the application allows residential addresses, times of isolation, and genetic relationships to be co-visualised for a sample set in a map view and a timeline. In 'single case exploration' mode, links between a single case and others can be displayed, with metadata displayed in tooltip like format (e.g. name, age, address, history, resistance, contact number). The user can 'Explore from here', upon which the current sample will become a new target sample. Thus, iterative exploration of transmission networks is possible. This application is being co-developed and evaluated between the University of Oxford and Public Health England TB control professionals.">Download
          Full Abstract</a></span></div>
    </div>
  </div>
  -->
</div>

<div class="talk">
  <table>
  <tr>
    <td width="300px">
      <a href="/2016/files/vis-107-thumbnail.jpg"> <img style="padding-right: 10px;" src="/2016/files/vis-107-thumbnail.jpg" alt="A Story of Reanimating an Embryonic Mouse Limb" height="250" width="250" /></a>
    </td>
  <td>
    <div class="ttitle">Poster: A Story of Reanimating an Embryonic Mouse Limb</div>
    <div><span class="tspeaker">Yong Wan, A. Kelsey Lewis, Gabrielle Kardon, Charles Hansen</span></div>
    <div>
      <p>People's impression of a mouse embryo seems to stay with a tiny and gummy-bear-like creature. In fact, mouse embryos have complicated anatomy. They have similar structures to their adults, but differences do exist. Mouse embryos are also invaluable models for biologists, who need a detailed map of their anatomy. Unfortunately, there was no such map (or atlas) that features the details and beauty often seen in those of human anatomy. If making a finely detailed atlas of mouse embryos is unprecedented, presenting both the result and workflow at the same time is more challenging. This poster is an attempt at the challenge, or at least part of it, quite literally ' the making of the anatomical atlas of an embryonic mouse limb. The poster presents the evolving process of an embryonic mouse limb atlas. Finely detailed structures are seen in the confocal photograph, the intermediate models and the final renderings. This is the first time that detailed structures of an embryonic mouse limb are imaged and modeled. It is also the first time that artist's tools are used in building embryo atlases in scientific research. It shows us the effectiveness of an artist's workflow and tools in solving a scientific problem. Advanced techniques in computer graphics are used to generate renderings of the volumetric data from confocal microscopy and the polygonal data of the atlas. Stories like this are always inspirational to both scientists and artists. We hope that this work prompts interdisciplinary collaborations and greater achievements can be made.</p>
    </div>
    <!--<div><span><a href="/2016/files/People's impression of a mouse embryo seems to stay with a tiny and gummy-bear-like creature. In fact, mouse embryos have complicated anatomy. They have similar structures to their adults, but differences do exist. Mouse embryos are also invaluable models for biologists, who need a detailed map of their anatomy. Unfortunately, there was no such map (or atlas) that features the details and beauty often seen in those of human anatomy. If making a finely detailed atlas of mouse embryos is unprecedented, presenting both the result and workflow at the same time is more challenging. This poster is an attempt at the challenge, or at least part of it, quite literally ' the making of the anatomical atlas of an embryonic mouse limb. The poster presents the evolving process of an embryonic mouse limb atlas. Finely detailed structures are seen in the confocal photograph, the intermediate models and the final renderings. This is the first time that detailed structures of an embryonic mouse limb are imaged and modeled. It is also the first time that artist's tools are used in building embryo atlases in scientific research. It shows us the effectiveness of an artist's workflow and tools in solving a scientific problem. Advanced techniques in computer graphics are used to generate renderings of the volumetric data from confocal microscopy and the polygonal data of the atlas. Stories like this are always inspirational to both scientists and artists. We hope that this work prompts interdisciplinary collaborations and greater achievements can be made.">Download Full Abstract</a></span></div>-->
  </td>
  </tr>
  </table>
  <!--
  <div class="clearfix float-my-children">
    <div><img src="/2016/files/vis-107-thumbnail.jpg" alt="A Story of Reanimating an Embryonic Mouse Limb" height="125" width="125"></div>
    <div>
      <div class="ttitle">Poster: A Story of Reanimating an Embryonic Mouse Limb</div>
      <div><span class="tspeaker">Yong Wan, A. Kelsey Lewis, Gabrielle Kardon, Charles Hansen</span></div>
      <div><span><a href="/2016/files/People's impression of a mouse embryo seems to stay with a tiny and gummy-bear-like creature. In fact, mouse embryos have complicated anatomy. They have similar structures to their adults, but differences do exist. Mouse embryos are also invaluable models for biologists, who need a detailed map of their anatomy. Unfortunately, there was no such map (or atlas) that features the details and beauty often seen in those of human anatomy. If making a finely detailed atlas of mouse embryos is unprecedented, presenting both the result and workflow at the same time is more challenging. This poster is an attempt at the challenge, or at least part of it, quite literally ' the making of the anatomical atlas of an embryonic mouse limb. The poster presents the evolving process of an embryonic mouse limb atlas. Finely detailed structures are seen in the confocal photograph, the intermediate models and the final renderings. This is the first time that detailed structures of an embryonic mouse limb are imaged and modeled. It is also the first time that artist's tools are used in building embryo atlases in scientific research. It shows us the effectiveness of an artist's workflow and tools in solving a scientific problem. Advanced techniques in computer graphics are used to generate renderings of the volumetric data from confocal microscopy and the polygonal data of the atlas. Stories like this are always inspirational to both scientists and artists. We hope that this work prompts interdisciplinary collaborations and greater achievements can be made.">Download
          Full Abstract</a></span></div>
    </div>
  </div>
  -->
</div>

<div class="talk">
  <table>
  <tr>
    <td width="300px">
      <a href="/2016/files/vis-108-thumbnail.png"> <img style="padding-right: 10px;" src="/2016/files/vis-108-thumbnail.png" alt="FluoRender: An Interactive Visualization System for 3D and 4D Confocal Microscopy Data in Neurobiology Research" height="250" width="250" /></a>
    </td>
  <td>
    <div class="ttitle">Poster: FluoRender: An Interactive Visualization System for 3D and 4D Confocal Microscopy Data in Neurobiology Research</div>
    <div><span class="tspeaker">Yong Wan, Hideo Otsuna, Chi-Bin Chien, Charles Hansen</span></div>
    <div>
      <p>FluoRender is an interactive tool for neurobiologists to visualize confocal microscopy data in their research. Multiple channels, detailed three-dimensional structures, and time-dependent sequences are the three major features of confocal microscopy data. With these features and usability in mind, we designed and engineered our system, which is now a free package for public download. We present the visualization pipeline and main features of our system for 3D/4D multi-channel confocal data visualization. Our system supports different input formats commonly seen for confocal microscopy. By minimizing pre-processing and optimizing data reading codes, it can read 3D/4D data with minimal latency. It has easy-to-use parameters for volume rendering effects, which are adjusted with real-time speed. It uses several image post-processing methods for detail enhancement, which are applied after volumetric data are rendered, and thus their adjustments are real-time even for 4D sequences. For multi-channel data, our system supports three different blending modes and channel grouping. Users can easily change all the settings and emphasize the most important features. Our presentation also includes several result images generated by our collaborating biologists.</p>
    </div>
    <!--<div><span><a href="/2016/files/FluoRender is an interactive tool for neurobiologists to visualize confocal microscopy data in their research. Multiple channels, detailed three-dimensional structures, and time-dependent sequences are the three major features of confocal microscopy data. With these features and usability in mind, we designed and engineered our system, which is now a free package for public download. We present the visualization pipeline and main features of our system for 3D/4D multi-channel confocal data visualization. Our system supports different input formats commonly seen for confocal microscopy. By minimizing pre-processing and optimizing data reading codes, it can read 3D/4D data with minimal latency. It has easy-to-use parameters for volume rendering effects, which are adjusted with real-time speed. It uses several image post-processing methods for detail enhancement, which are applied after volumetric data are rendered, and thus their adjustments are real-time even for 4D sequences. For multi-channel data, our system supports three different blending modes and channel grouping. Users can easily change all the settings and emphasize the most important features. Our presentation also includes several result images generated by our collaborating biologists.">Download Full Abstract</a></span></div>-->
  </td>
  </tr>
  </table>
  <!--
  <div class="clearfix float-my-children">
    <div><img src="/2016/files/vis-108-thumbnail.png" alt="FluoRender: An Interactive Visualization System for 3D and 4D Confocal Microscopy Data in Neurobiology Research" height="125" width="125"></div>
    <div>
      <div class="ttitle">Poster: FluoRender: An Interactive Visualization System for 3D and 4D Confocal Microscopy Data in Neurobiology Research</div>
      <div><span class="tspeaker">Yong Wan, Hideo Otsuna, Chi-Bin Chien, Charles Hansen</span></div>
      <div><span><a href="/2016/files/FluoRender is an interactive tool for neurobiologists to visualize confocal microscopy data in their research. Multiple channels, detailed three-dimensional structures, and time-dependent sequences are the three major features of confocal microscopy data. With these features and usability in mind, we designed and engineered our system, which is now a free package for public download. We present the visualization pipeline and main features of our system for 3D/4D multi-channel confocal data visualization. Our system supports different input formats commonly seen for confocal microscopy. By minimizing pre-processing and optimizing data reading codes, it can read 3D/4D data with minimal latency. It has easy-to-use parameters for volume rendering effects, which are adjusted with real-time speed. It uses several image post-processing methods for detail enhancement, which are applied after volumetric data are rendered, and thus their adjustments are real-time even for 4D sequences. For multi-channel data, our system supports three different blending modes and channel grouping. Users can easily change all the settings and emphasize the most important features. Our presentation also includes several result images generated by our collaborating biologists.">Download
          Full Abstract</a></span></div>
    </div>
  </div>
  -->
</div>

<div class="talk">
  <table>
  <tr>
    <td width="300px">
      <a href="/2016/files/vis-109-thumbnail.png"> <img style="padding-right: 10px;" src="/2016/files/vis-109-thumbnail.png" alt="MetroNome: Visual Data Exploration for a Genomic Data Repository" height="250" width="250" /></a>
    </td>
  <td>
    <div class="ttitle">Poster: MetroNome: Visual Data Exploration for a Genomic Data Repository</div>
    <div><span class="tspeaker">Christian Stolte, Dorian Leary, Dimitrije Jeremovic, Kevin Shi, Sudeep Mehrotra, Nina Lapchyk, Avinash Abhyankar, Ann-Katrin Emde, Shailu Gareya, Toby Bloom</span></div>
    <div>
      <p>In recent years the cost of genomic sequencing has dropped to a level that allows hospitals to make it a routine procedure. But science still has much to learn before doctors can use a patient's genome as a diagnostic aid, or select a treatment based on genotype. The big gap in knowledge is the connection between genotypes and phenotypes. Besides disease-specific resources, such as The Cancer Genome Atlas (TCGA), and reference data from healthy populations (think 1,000 Genomes Project), researchers need databases that allow them to connect everyday electronic health records with genomic information.  MetroNome is a data warehouse that brings all these resources together. It has a web-based exploratory interface to correlate genotypes with phenotypes. The system accepts genomic sequence and clinical data from any research project. Participating researchers can explore their data in an interactive visual interface and organize data along many dimensions.  We visualize genomic variants in three different contexts: 1. per chromosome, in a sample frequency histogram; 2. per gene, mapping variants and their frequency onto a gene diagram displaying both genomic sequence and the resulting protein transcript;  3. in a sample/gene matrix, showing 5 dimensions per variant. For clinical data, we chose parallel coordinate and parallel set diagrams to display numerical and categorical dimensions. Both can show many dimensions at once and allow users to spot trends and correlations. These diagrams also function as selection tools to hone in on sample sets or genomic regions with specific attributes.</p>
    </div>
    <!--<div><span><a href="/2016/files/In recent years the cost of genomic sequencing has dropped to a level that allows hospitals to make it a routine procedure. But science still has much to learn before doctors can use a patient's genome as a diagnostic aid, or select a treatment based on genotype. The big gap in knowledge is the connection between genotypes and phenotypes. Besides disease-specific resources, such as The Cancer Genome Atlas (TCGA), and reference data from healthy populations (think 1,000 Genomes Project), researchers need databases that allow them to connect everyday electronic health records with genomic information.  MetroNome is a data warehouse that brings all these resources together. It has a web-based exploratory interface to correlate genotypes with phenotypes. The system accepts genomic sequence and clinical data from any research project. Participating researchers can explore their data in an interactive visual interface and organize data along many dimensions.  We visualize genomic variants in three different contexts: 1. per chromosome, in a sample frequency histogram; 2. per gene, mapping variants and their frequency onto a gene diagram displaying both genomic sequence and the resulting protein transcript;  3. in a sample/gene matrix, showing 5 dimensions per variant. For clinical data, we chose parallel coordinate and parallel set diagrams to display numerical and categorical dimensions. Both can show many dimensions at once and allow users to spot trends and correlations. These diagrams also function as selection tools to hone in on sample sets or genomic regions with specific attributes.">Download Full Abstract</a></span></div>-->
  </td>
  </tr>
  </table>
  <!--
  <div class="clearfix float-my-children">
    <div><img src="/2016/files/vis-109-thumbnail.png" alt="MetroNome: Visual Data Exploration for a Genomic Data Repository" height="125" width="125"></div>
    <div>
      <div class="ttitle">Poster: MetroNome: Visual Data Exploration for a Genomic Data Repository</div>
      <div><span class="tspeaker">Christian Stolte, Dorian Leary, Dimitrije Jeremovic, Kevin Shi, Sudeep Mehrotra, Nina Lapchyk, Avinash Abhyankar, Ann-Katrin Emde, Shailu Gareya, Toby Bloom</span></div>
      <div><span><a href="/2016/files/In recent years the cost of genomic sequencing has dropped to a level that allows hospitals to make it a routine procedure. But science still has much to learn before doctors can use a patient's genome as a diagnostic aid, or select a treatment based on genotype. The big gap in knowledge is the connection between genotypes and phenotypes. Besides disease-specific resources, such as The Cancer Genome Atlas (TCGA), and reference data from healthy populations (think 1,000 Genomes Project), researchers need databases that allow them to connect everyday electronic health records with genomic information.  MetroNome is a data warehouse that brings all these resources together. It has a web-based exploratory interface to correlate genotypes with phenotypes. The system accepts genomic sequence and clinical data from any research project. Participating researchers can explore their data in an interactive visual interface and organize data along many dimensions.  We visualize genomic variants in three different contexts: 1. per chromosome, in a sample frequency histogram; 2. per gene, mapping variants and their frequency onto a gene diagram displaying both genomic sequence and the resulting protein transcript;  3. in a sample/gene matrix, showing 5 dimensions per variant. For clinical data, we chose parallel coordinate and parallel set diagrams to display numerical and categorical dimensions. Both can show many dimensions at once and allow users to spot trends and correlations. These diagrams also function as selection tools to hone in on sample sets or genomic regions with specific attributes.">Download
          Full Abstract</a></span></div>
    </div>
  </div>
  -->
</div>

<div class="talk">
  <table>
  <tr>
    <td width="300px">
      <a href="/2016/files/vis-110-thumbnail.png"> <img style="padding-right: 10px;" src="/2016/files/vis-110-thumbnail.png" alt="Visual Analysis System for Clustering Dementia Patients Based on Similarity of Dementia Phase Changing pattern" height="250" width="250" /></a>
    </td>
  <td>
    <div class="ttitle">Poster: Visual Analysis System for Clustering Dementia Patients Based on Similarity of Dementia Phase Changing pattern</div>
    <div><span class="tspeaker">Mubashar Karim Raja, Youngbeom Choi, Wooseok Song, Kyungwon Lee</span></div>
    <div>
      <p>In this study we introduce a visual analysis system to facilitate the decision making system while diagnosing dementia patients. Our approach first applies the bar graph to visualize patients result records at each visit independently. These result records are the variables used when examining patients with dementia, obtained from CREDOS (Clinical Research Center for Dementia of South Korea). We then apply cluster analysis to visualize patient clusters dynamics over time based on their similarity of phase changing pattern. This allows user to identify patients' clusters and their phase changing patterns, inspect and compare findings and test variables between different patient clusters. The result records compiled include data for each patient at five discrete time points. Bar graph visualization has five discrete time point scores that help the user to analyze the progress of patients. User can select the variable from the drop down menu, which seems more important to user. Our work allows users to see multi-level clustering at one sight. There are so many test results, which need to be studied closely in order to diagnose which phase of dementia a patient has. Although the outset of dementia cannot be stopped or reversed, but if it is diagnosed at early stage it allow people with dementia a better chance of benefiting from treatment. For this reason, early detection is highly important for patients. It is however difficult to provide details on the patient's status via current diagnosis indicators, since it is rather widely categorized as Alzheimer disease, vascular dementia.</p>
    </div>
    <!--<div><span><a href="/2016/files/In this study we introduce a visual analysis system to facilitate the decision making system while diagnosing dementia patients. Our approach first applies the bar graph to visualize patients result records at each visit independently. These result records are the variables used when examining patients with dementia, obtained from CREDOS (Clinical Research Center for Dementia of South Korea). We then apply cluster analysis to visualize patient clusters dynamics over time based on their similarity of phase changing pattern. This allows user to identify patients' clusters and their phase changing patterns, inspect and compare findings and test variables between different patient clusters. The result records compiled include data for each patient at five discrete time points. Bar graph visualization has five discrete time point scores that help the user to analyze the progress of patients. User can select the variable from the drop down menu, which seems more important to user. Our work allows users to see multi-level clustering at one sight. There are so many test results, which need to be studied closely in order to diagnose which phase of dementia a patient has. Although the outset of dementia cannot be stopped or reversed, but if it is diagnosed at early stage it allow people with dementia a better chance of benefiting from treatment. For this reason, early detection is highly important for patients. It is however difficult to provide details on the patient's status via current diagnosis indicators, since it is rather widely categorized as Alzheimer disease, vascular dementia.">Download Full Abstract</a></span></div>-->
  </td>
  </tr>
  </table>
  <!--
  <div class="clearfix float-my-children">
    <div><img src="/2016/files/vis-110-thumbnail.png" alt="Visual Analysis System for Clustering Dementia Patients Based on Similarity of Dementia Phase Changing pattern" height="125" width="125"></div>
    <div>
      <div class="ttitle">Poster: Visual Analysis System for Clustering Dementia Patients Based on Similarity of Dementia Phase Changing pattern</div>
      <div><span class="tspeaker">Mubashar Karim Raja, Youngbeom Choi, Wooseok Song, Kyungwon Lee</span></div>
      <div><span><a href="/2016/files/In this study we introduce a visual analysis system to facilitate the decision making system while diagnosing dementia patients. Our approach first applies the bar graph to visualize patients result records at each visit independently. These result records are the variables used when examining patients with dementia, obtained from CREDOS (Clinical Research Center for Dementia of South Korea). We then apply cluster analysis to visualize patient clusters dynamics over time based on their similarity of phase changing pattern. This allows user to identify patients' clusters and their phase changing patterns, inspect and compare findings and test variables between different patient clusters. The result records compiled include data for each patient at five discrete time points. Bar graph visualization has five discrete time point scores that help the user to analyze the progress of patients. User can select the variable from the drop down menu, which seems more important to user. Our work allows users to see multi-level clustering at one sight. There are so many test results, which need to be studied closely in order to diagnose which phase of dementia a patient has. Although the outset of dementia cannot be stopped or reversed, but if it is diagnosed at early stage it allow people with dementia a better chance of benefiting from treatment. For this reason, early detection is highly important for patients. It is however difficult to provide details on the patient's status via current diagnosis indicators, since it is rather widely categorized as Alzheimer disease, vascular dementia.">Download
          Full Abstract</a></span></div>
    </div>
  </div>
  -->
</div>

<div class="talk">
  <table>
  <tr>
    <td width="300px">
      <a href="/2016/files/vis-112-thumbnail.png"> <img style="padding-right: 10px;" src="/2016/files/vis-112-thumbnail.png" alt="The JAX Synteny Browser for Mouse-Human Comparative Genomics" height="250" width="250" /></a>
    </td>
  <td>
    <div class="ttitle">Poster: The JAX Synteny Browser for Mouse-Human Comparative Genomics</div>
    <div><span class="tspeaker">Mei Xiao, Keith Sheppard, Paul Hale, Govindarajan Kunde-Ramamoorthy, Joel Richardson, Carol Bult</span></div>
    <div>
      <p>Conserved synteny is a description for when gene content and order of a region of an organism's genome is conserved in the genome of a different species. Visualizing and navigating between shared syntenic blocks is a common task for comparative genetics.  For example, researchers may wish to start with the genome location of a trait mapped in a GWAS study to the corresponding genome location in mouse as part of a strategy to identify candidate genome features for the human trait.  Although many visualization tools have been developed for navigating conserved syntenic regions, existing tools are limited to visualization of the genome features and do not support interactions with the annotations of genome features displayed. To address this usability gap, we have developed a new interactive web-based synteny browser. The JAX Synteny Browser includes support for searching for and displaying genome features according to their biological annotations. The tool has been implemented for mouse and human but the design is intentionally generic and can be applied to any two genomes.  Using this browser, users can launch navigation from a user-selected reference genome using genome coordinates or results of searches for mapped features of interest. Once a genome region has been selected, users can view the features that are annotated in specific syntenic blocks and adjust the display of the features based on their annotations. Combining visualization with genome feature interaction makes this tool unique among the currently available options for visualization of conserved synteny. Supported in part by: U41 HG000330</p>
    </div>
    <!--<div><span><a href="/2016/files/Conserved synteny is a description for when gene content and order of a region of an organism's genome is conserved in the genome of a different species. Visualizing and navigating between shared syntenic blocks is a common task for comparative genetics.  For example, researchers may wish to start with the genome location of a trait mapped in a GWAS study to the corresponding genome location in mouse as part of a strategy to identify candidate genome features for the human trait.  Although many visualization tools have been developed for navigating conserved syntenic regions, existing tools are limited to visualization of the genome features and do not support interactions with the annotations of genome features displayed. To address this usability gap, we have developed a new interactive web-based synteny browser. The JAX Synteny Browser includes support for searching for and displaying genome features according to their biological annotations. The tool has been implemented for mouse and human but the design is intentionally generic and can be applied to any two genomes.  Using this browser, users can launch navigation from a user-selected reference genome using genome coordinates or results of searches for mapped features of interest. Once a genome region has been selected, users can view the features that are annotated in specific syntenic blocks and adjust the display of the features based on their annotations. Combining visualization with genome feature interaction makes this tool unique among the currently available options for visualization of conserved synteny. Supported in part by: U41 HG000330">Download Full Abstract</a></span></div>-->
  </td>
  </tr>
  </table>
  <!--
  <div class="clearfix float-my-children">
    <div><img src="/2016/files/vis-112-thumbnail.png" alt="The JAX Synteny Browser for Mouse-Human Comparative Genomics" height="125" width="125"></div>
    <div>
      <div class="ttitle">Poster: The JAX Synteny Browser for Mouse-Human Comparative Genomics</div>
      <div><span class="tspeaker">Mei Xiao, Keith Sheppard, Paul Hale, Govindarajan Kunde-Ramamoorthy, Joel Richardson, Carol Bult</span></div>
      <div><span><a href="/2016/files/Conserved synteny is a description for when gene content and order of a region of an organism's genome is conserved in the genome of a different species. Visualizing and navigating between shared syntenic blocks is a common task for comparative genetics.  For example, researchers may wish to start with the genome location of a trait mapped in a GWAS study to the corresponding genome location in mouse as part of a strategy to identify candidate genome features for the human trait.  Although many visualization tools have been developed for navigating conserved syntenic regions, existing tools are limited to visualization of the genome features and do not support interactions with the annotations of genome features displayed. To address this usability gap, we have developed a new interactive web-based synteny browser. The JAX Synteny Browser includes support for searching for and displaying genome features according to their biological annotations. The tool has been implemented for mouse and human but the design is intentionally generic and can be applied to any two genomes.  Using this browser, users can launch navigation from a user-selected reference genome using genome coordinates or results of searches for mapped features of interest. Once a genome region has been selected, users can view the features that are annotated in specific syntenic blocks and adjust the display of the features based on their annotations. Combining visualization with genome feature interaction makes this tool unique among the currently available options for visualization of conserved synteny. Supported in part by: U41 HG000330">Download
          Full Abstract</a></span></div>
    </div>
  </div>
  -->
</div>


</div>



<footer class="page-footer">
    <div class="container">
        <div class="row">
            <div class="col l4 m4 s12">
                <img src="/2016/images/logo-white.svg" width="140">
            </div>

            <div class="col l4 m4 s12">
                <h5 class="white-text">Sponsors</h5>
                <ul>
                    <li><a href="https://www.rstudio.com/" target="_blank">RStudio</a></li>
                    <li><a href="https://www.sbgenomics.com/" target="_blank">Seven Bridges</a></li>
                    <li><a href="http://www.nvidia.com/content/global/global.php" target="_blank">nvidia</a></li>
                    <li><a href="http://f1000research.com/" target="_blank">F1000</a></li>
                </ul>
            </div>

            <div class="col l4 m4 s12">
                <h5 class="white-text">Links</h5>
                <ul>
                    <li><a href="http://ieeevis.org/" target="_blank">IEEE VIS</a></li>
                    <li><a href="https://www.iscb.org/ismb2016" target="_blank">ISMB</a></li>
                    <li><a href="http://www.biomedcentral.com/bmcbioinformatics/series/BioVis2014" target="_blank">BMC
                        Thematic Series</a></li>
                </ul>
            </div>
        </div>

        <div class="footer-copyright center-align">

            © 6th Symposium on Biological Data Visualization | Designed by <a href="http://www.antarctic-design.co.uk"
                                                                              target="_blank">Antarctic Design</a>.


        </div>
    </div>

</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.97.5/js/materialize.min.js"></script>


<script>
    $(".button-collapse").sideNav();
    $(".dropdown-button").dropdown();
</script>




<!-- Google Analytics -->
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-22015250-1', 'auto');
    ga('send', 'pageview');



    (function (){
        var links = document.getElementsByTagName('a');
        var myLink = null;
        var startWith = null;

        for(var i = 0; i < links.length; ++i) {
            myLink = links[i];

            startWith = myLink.getAttribute('href').slice(0, 1);

            if (startWith!="/" && startWith!="#"){
                addListener(myLink,'mousedown',function(){

                    console.log("a:", this.getAttribute('href'))
                    ga('send', 'event', 'link', 'click', this.getAttribute('href'));

                })
            }

        }
    })();



    /**
     * Utility to wrap the different behaviors between W3C-compliant browsers
     * and IE when adding event handlers.
     *
     * @param {Object} element Object on which to attach the event listener.
     * @param {string} type A string representing the event type to listen for
     *     (e.g. load, click, etc.).
     * @param {function()} callback The function that receives the notification.
     */
    function addListener(element, type, callback) {
        if (element.addEventListener) element.addEventListener(type, callback);
        else if (element.attachEvent) element.attachEvent('on' + type, callback);
    }




</script>
<!-- End Google Analytics -->


</body>
</html>
